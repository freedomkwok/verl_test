{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ee4efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freedomkwokmacbookpro/miniforge3/envs/openmanus-rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 12692.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/freedomkwokmacbookpro/Github/Kaggle/OpenRL/models/Qwen_1_5B_base'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "model_base_path = \"./models/Qwen_1_5B_base\" \n",
    "snapshot_download(repo_id=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", local_dir=model_base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd8c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openmanus_rl.agentgym.agentenv.agentenv.prompts.gmail_calander import prompt as gmail_prompt, owner_tag, owner_email, owner_name, owner_perfernce, num_of_sentences, today\n",
    "from openmanus_rl.agentgym.agentenv.agentenv.controller.task import ConversationMessage\n",
    "from datetime import datetime\n",
    "\n",
    "conversation_start: list[dict[str, str]] = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": gmail_prompt\n",
    "                    .replace(owner_tag, \"owners\")\n",
    "                    .replace(owner_email, \"freedomkwok2010@gmail.com\")\n",
    "                    .replace(owner_name, \"Richard Guo\")\n",
    "                    .replace(today, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                    .replace(owner_perfernce, \"I try to schedule meeting at the morning\")\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is my avaliability tomorrow\"\n",
    "            }\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 14.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_trained = \"/data/models/QWEN1_5B_MOD1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_trained, trust_remote_code=True)\n",
    "prompt_text = tokenizer.apply_chat_template(conversation_start, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_trained, trust_remote_code=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf702db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>\n",
      "You are an autonomous intelligent agent for managing Gmail calendars. There are two types of users who interact with you:the owner (who controls the calendar) and others (who do not). When the user is the owner, use list_events to find events. For others, use check_availability or find_free_time to find available time slots in the owner's calendar. \n",
      "Current User:owners\n",
      "Owner Email:freedomkwok2010@gmail.com\n",
      "Owner Name:Richard Guo\n",
      "Today_Date:2025-07-09 12:43:22\n",
      "Owner preference:I try to schedule meeting at the morning\n",
      "\n",
      "Privacy:fields in private_field (creator, visibility, attendees, hangoutLink, summary, description, location) are omitted from outputs for owner.\n",
      "When others schedule with the owner, please follow owner's preferences as closely as possible\n",
      "We detail name, description, input(parameters) and output(returns) of each action as follows:\n",
      "\n",
      "Actions:\n",
      "Name:list_calendars\n",
      "Description:List all available calendars in the user's Gmail account.\n",
      "Parameters:\n",
      "- None\n",
      "Returns:\n",
      "- A list of calendar objects, each with properties:\n",
      "- id (Type:string):Calendar ID\n",
      "- summary (Type:string):Calendar name\n",
      "- timeZone (Type:string):Time zone of the calendar\n",
      "- primary (Type:boolean):Whether this is the primary calendar\n",
      "\n",
      "Name:list_events\n",
      "Description:List events in a specified calendar within a time range(typically covering one or two days. If no relevant events are found, the time range may be extended forward to continue searching, excluding the previously searched range). This action should mainly be used by the owner.\n",
      "Parameters (Type:dict):\n",
      "- calendar_id (Type:string, optional, default \"primary\"):The calendar to list events from\n",
      "- time_min (Type:string, required, ISO 8601):Start of the time range (default:utcnow)\n",
      "- time_max (Type:string, required ISO 8601):End of the time range (default:31 days from utcnow)\n",
      "- show_hidden (Type:boolean, optional, default False):Whether to show hidden invitations\n",
      "Returns:\n",
      "- A list of event objects, each with properties:\n",
      "- id (Type:string):Event ID\n",
      "- creator\n",
      "- visibility\n",
      "- attendees\n",
      "- summary (Type:string):Event title\n",
      "- start (Type:string):Start time\n",
      "- end (Type:string):End time\n",
      "Note:creator, visibility, attendees, hangoutLink, summary, and other fields may be omitted if is_owner is False (see Privacy Note above).\n",
      "\n",
      "Name:create_event\n",
      "Description:Create a new event in a calendar.\n",
      "Parameters (Type:dict):\n",
      "- calendar_id (Type:string, optional, default \"primary\"):The calendar to create the event in\n",
      "- summary (Type:string, optional, default \"New Event\"):Event title\n",
      "- description (Type:string, optional):Event description\n",
      "- start_time (Type:string, required, ISO 8601):Event start time (default:utcnow) \n",
      "- end_time (Type:string, required, ISO 8601):Event end time (default:utcnow) \n",
      "- timezone (Type:string, optional, default \"UTC\"):Time zone\n",
      "- attendees (Type:string, optional):Comma-separated emails of attendees\n",
      "Returns:\n",
      "- A string with the link to the created event\n",
      "\n",
      "Name:update_event\n",
      "Description:Update an existing event in a calendar.\n",
      "Parameters (Type:dict):\n",
      "- calendar_id (Type:string, optional, default \"primary\"):The calendar containing the event\n",
      "- event_id (Type:string, required):The ID of the event to update\n",
      "- summary (Type:string, optional):New event title\n",
      "- description (Type:string, optional):New event description\n",
      "- start_time (Type:string, optional, ISO format):New start time\n",
      "- end_time (Type:string, optional, ISO format):New end time\n",
      "- attendees (Type:string, optional):Comma-separated emails of attendees\n",
      "- responseStatus (Type:string, optional):Attendee response status (accepted, declined, tentative, needsAction)\n",
      "Returns:\n",
      "- A string with the link to the updated event\n",
      "\n",
      "Name:delete_event\n",
      "Description:Delete an event from the primary calendar.\n",
      "Parameters (Type:dict):\n",
      "- event_id (Type:string, required):The ID of the event to delete\n",
      "Returns:\n",
      "- A string confirming deletion of the event\n",
      "\n",
      "Name:check_availability\n",
      "Description:Check if a calendar is available (no events) during a given time range(typically covering one or two days. If no relevant events are found, the time range may be extended forward to continue searching, excluding the previously searched range). This action should mainly be used by the owner.\n",
      "Parameters:\n",
      "- calendar_id (Type:string, optional, default \"primary\"):The calendar to check\n",
      "- time_min (Type:string, required, ISO 8601):Start of the time range\n",
      "- time_max (Type:string, required, ISO 8601):End of the time range\n",
      "Returns:\n",
      "- A string indicating if the calendar is available or listing busy times\n",
      "\n",
      "Name:find_free_time\n",
      "Description:Find free time slots in a calendar within a time range(typically covering one or two days. If no relevant events are found, the time range may be extended forward to continue searching, excluding the previously searched range). This action should mainly be used by the owner. \n",
      "Parameters (Type:dict):\n",
      "- calendar_id (Type:string, optional, default \"primary\"):The calendar to check\n",
      "- duration_minutes (Type:integer, optional, default 30):Minimum duration of free slot\n",
      "- time_min (Type:string, required, ISO 8601, default now):Start of the time range\n",
      "- time_max (Type:string, required, ISO 8601, default 7 days from now):End of the time range\n",
      "Returns:\n",
      "- A list of free time slots, each with start, end, and duration_minutes\n",
      "\n",
      "Name:get_event_details\n",
      "Description:Get detailed information about a specific event.\n",
      "Parameters (Type:dict):\n",
      "- event_id (Type:string, required):The ID of the event\n",
      "- timeZone (Type:string, optional, default \"UTC\"):Time zone for the event\n",
      "Returns:\n",
      "- An object with event details (id, summary, description, start, end, location, etc.), but fields such as creator, visibility, attendees, hangoutLink, summary, description, location may be omitted if is_owner is False (see Privacy Note above).\n",
      "\n",
      "Name:search_people\n",
      "Description:Search for all matching names and email addresses by a given name using Google People API. This action should mainly be used by the owner. pick the one that matches the most, if not sure feedback to the owner to verify\n",
      "Parameters (Type:dict):\n",
      "- query (Type:string, required):put in the name, title, organization, email as query to search\n",
      "Returns:\n",
      "- A JSON-formatted string listing all matched persons, each with displayName, email, and resourceName fields.\n",
      "\n",
      "Name:add_contact\n",
      "Description:Add a new contact to the user's Google Contacts. This action should mainly be used by the owner.\n",
      "Parameters (Type:dict):\n",
      "- full_name (Type:string, required):The full name of the contact\n",
      "- email (Type:string, required):The email address of the contact\n",
      "- organization (Type:string, optional):The organization of the contact\n",
      "- title (Type:string, optional):The title of the contact\n",
      "Returns:\n",
      "- A string confirming the contact was created, including the resourceName, or an error message.\n",
      "\n",
      "Name:update_contact\n",
      "Description:Update an existing contact in the user's Google Contacts by resourceName. This action should mainly be used by the owner.\n",
      "Parameters (Type:dict):\n",
      "- resourceName (Type:string, required):The resourceName to identify the contact\n",
      "- etag (Type:string, required):The etag to identify the contact\n",
      "- displayName (Type:string, optional):The new display name for the contact\n",
      "- email (Type:string, optional):The new email address for the contact\n",
      "- organization (Type:string, optional):The new organization for the contact\n",
      "- title (Type:string, optional):The new title for the contact\n",
      "Returns:\n",
      "- A string confirming the contact was updated, including the resourceName, or an error message.\n",
      "\n",
      "Name:finish\n",
      "Description:Finish the current task and return the final answer.\n",
      "Parameters:\n",
      "- answer (string, required):Summarize what you have done or discovered. This should be a concise description of your work or findings.\n",
      "- goal_type (string, required):\n",
      "Returns:\n",
      "- Return a clear and brief string confirming task completion along with your final answer.\n",
      "\n",
      "Things you shoul pay attentions:\n",
      "Do not add contact if people already exists or have the same info, use update_contact only if new info present.\n",
      "If an exception occurs during observation, check whether it’s caused by invalid parameters. If so, update the parameters accordingly.\n",
      "Before create event, always make sure there is no such event overlap or if there is event already set within the same perod, make sure all attendees are included.\n",
      "Do not generate them yourself as they may be incorrect. If you are finished, you will call the \"finish\" action.\n",
      "When others try to access the owner’s personal information, politely respond that you’re only allowed to help find available time slots for scheduling — and cannot provide any additional personal details.\n",
      "Please provide your thought to solve the question. You should give the thought with no more than <num_of_sentences> sentences. You need to give your thought together with your action!\n",
      "\n",
      "Your response must be in the format of:\n",
      "Thought:[your thought]\n",
      "Action:[your action] with Action Input:[your action input]\n",
      "Note:Your action input must be valid JSON, with no backticks, no parentheses, no extra quotes, and no escape characters. Only include parameters that are needed. Example:Action:create_event with Action Input:{\"xxx\":\"xxx\"}\n",
      "<｜User｜>What is my avaliability tomorrow<｜Assistant｜><think>\n",
      "The current date is July 9, 2025. I will check the owner's calendar for availability on July 10, 2025. \n",
      "Action:check_availability with Action Input:{\"calendar_id\":\"primary\",\"time_min\":\"2025-07-10T00:00:00Z\",\"time_max\":\"2025-07-11T00:00:00Z\"}\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=4300, temperature=0.6)\n",
    "\n",
    "# Decode and print result\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "def print_trainable_params(model, note=\"\"):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"--- {note} ---\")\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Frozen parameters: {total - trainable:,}\")\n",
    "    print()\n",
    "\n",
    "def count_named(model, pred):\n",
    "    return sum(p.numel() for n, p in model.named_parameters() if pred(n, p))\n",
    "\n",
    "# Paths\n",
    "base_model_path = \"/data/models/Qwen_1_5B\"\n",
    "adapter_path = \"/data/models/SFT_0718_0442_55\"\n",
    "output_dir = \"/data/models/QWEN1_5B_MOD1\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "\n",
    "# Base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# IMPORTANT: freeze base before adding adapter\n",
    "base_model.requires_grad_(False)\n",
    "base_model.eval()\n",
    "\n",
    "print_trainable_params(base_model, note=\"Before attaching adapter (base frozen)\")\n",
    "\n",
    "print(\"Loading adapter K0...\")\n",
    "peft_model = PeftModel.from_pretrained(base_model, adapter_path, adapter_name=\"K0\")\n",
    "peft_model.set_adapter(\"K0\")\n",
    "\n",
    "# Inspect adapter-specific trainables (e.g., lora layers)\n",
    "lora_trainable = count_named(\n",
    "    peft_model,\n",
    "    lambda n, p: p.requires_grad and (\"lora_\" in n or \"lora\" in n or \"adapter\" in n)\n",
    ")\n",
    "print(f\"Adapter-trainable parameter count (approx, name-filtered): {lora_trainable:,}\")\n",
    "print_trainable_params(peft_model, note=\"With adapter loaded (should show only adapter trainable)\")\n",
    "\n",
    "# Merge\n",
    "print(\"Merging adapter K0...\")\n",
    "peft_model.merge_adapter()\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "print_trainable_params(merged_model, note=\"After merging and unloading (all frozen)\")\n",
    "\n",
    "# Optional: verify weight changes (norm diff) on a few layers\n",
    "with torch.no_grad():\n",
    "    # Example layer names, adjust to your model’s naming\n",
    "    for layer_name in [\"model.embed_tokens.weight\", \"lm_head.weight\"]:\n",
    "        if hasattr(merged_model, \"get_parameter\"):\n",
    "            try:\n",
    "                w = merged_model.get_parameter(layer_name)\n",
    "                print(f\"{layer_name}: shape={tuple(w.shape)}, dtype={w.dtype}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# Save\n",
    "merged_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Merged model saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch, os\n",
    "\n",
    "base_id = \"/workspace/Qwen_1_5B\"\n",
    "A_path  = \"/workspace/output/Qwen_1_5B/SFT_0815_0701_70\"\n",
    "B_path  = \"/workspace/output/Qwen_1_5B/SFT_0815_0739_65\"\n",
    "C_path  = \"/workspace/output/Qwen_1_5B/SFT_0815_0817_60\"\n",
    "output_dir = \"/data/models/QWEN1_5B_0815_ABC\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(base_id, trust_remote_code=True)\n",
    "\n",
    "# load base (fp16 is fine). device_map=\"auto\" is OK for merge, but we’ll move to CPU before save.\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# load 3 adapters\n",
    "model = PeftModel.from_pretrained(base, A_path, adapter_name=\"A\")\n",
    "model.load_adapter(B_path, adapter_name=\"B\")\n",
    "model.load_adapter(C_path, adapter_name=\"C\")\n",
    "\n",
    "# blend them into a new logical adapter\n",
    "model.add_weighted_adapter(\n",
    "    adapters=[\"A\", \"B\", \"C\"],\n",
    "    weights=[0.6, 0.2, 0.2],\n",
    "    adapter_name=\"ABC_blend\",\n",
    ")\n",
    "model.set_adapter(\"ABC_blend\")\n",
    "\n",
    "# MERGE: returns the plain HF model (no adapters)\n",
    "merged = model.merge_and_unload()      # <-- capture the return!\n",
    "\n",
    "# (optional) sanity: ensure it’s not a PeftModel anymore\n",
    "print(\"Type after merge:\", type(merged))\n",
    "\n",
    "# consolidate to CPU so save_pretrained writes a proper set of files\n",
    "merged = merged.to(\"cpu\")\n",
    "\n",
    "# write safetensors; bump shard size if you want a single file\n",
    "merged.save_pretrained(\n",
    "    output_dir,\n",
    "    safe_serialization=True,           # <-- write .safetensors\n",
    "    max_shard_size=\"10GB\",             # optional: try to avoid multiple shards\n",
    ")\n",
    "tok.save_pretrained(output_dir)\n",
    "print(\"Saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -c \"import torch; torch.cuda.empty_cache(); torch.cuda.ipc_collect(); print('✅ CUDA memory cache cleared.')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31434617",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m vllm.entrypoints.openai.api_server \\\n",
    "  --model /workspace/qwen1_5B_K3_BF16 \\\n",
    "  --dtype bfloat16 \\\n",
    "  --port 38000 \\\n",
    "  --max-model-len 10000 \\\n",
    "  --gpu-memory-utilization 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmanus-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
