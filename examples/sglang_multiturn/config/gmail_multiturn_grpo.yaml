hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  max_prompt_length: 8000
  max_response_length: 1000
  train_batch_size: 2
  return_raw_chat: True

actor_rollout_ref:
  hybrid_engine: True
  rollout:
    name: sglang
    mode: async
    load_format: dummy_dtensor
    enforce_eager: False
    free_cache_engine: True
    
    # Model and distributed configs
    dtype: bfloat16
    tensor_model_parallel_size: 1
    gpu_memory_utilization: 0.5
    ignore_eos: False
    max_num_batched_tokens: 8192

    # Length configs (correct rollout fields)
    prompt_length: 6000
    response_length: 1000
    max_model_len: 7000  # prompt_length + response_length
    
    # Multi-turn configs
    multi_turn:
      enable: True
      max_assistant_turns: 10
      max_user_turns: 10
      tool_config_path: null
      interaction_config_path: examples/sglang_multiturn/config/interaction_config/gmail_interaction_config.yaml
      use_inference_chat_template: false
      tokenization_sanity_check_mode: disable

    # Sampling configs
    calculate_log_probs: true
    temperature: 0.7
    top_p: 0.9
    top_k: -1
    n: 1
    do_sample: true
      
